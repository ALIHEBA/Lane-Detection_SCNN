{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nimport cv2\n#experiment with single image and text file\nimg_file = \"../input/culane/driver_161_90frame/06030822_0756.MP4/00000.jpg\"\ntext_file = \"../input/culane/driver_161_90frame/06030822_0756.MP4/00000.lines.txt\"\n\ndef remove_newlines(fname):\n    data=[]\n    coordinates =[]\n    flist = open(fname).readlines()\n    for s in flist:\n        data.extend([d for d in s.rstrip('\\n').split(\" \")  if d!=''])\n    \n    data = np.array(data).astype(np.float32)\n        \n    for idx in range(0,len(data),2):\n        coordinates.append(data[idx:idx+2])\n    if(len(data)==0):\n        return None , None  , 0 , 0\n    \n    else:\n\n        mean_val = np.mean(data)\n        std_val = np.std(data)\n        return coordinates , data , mean_val  , std_val\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-06-27T22:04:05.677854Z","iopub.execute_input":"2022-06-27T22:04:05.678163Z","iopub.status.idle":"2022-06-27T22:04:06.66528Z","shell.execute_reply.started":"2022-06-27T22:04:05.678133Z","shell.execute_reply":"2022-06-27T22:04:06.664515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets create a image file list with images and text files\nfrom os import walk\n\nimg_files = []\nlabel_data=[]\nmean_array=[]\nstd_array = []\ncoordinate_list=[]\nfor dirpath, dirnames, filenames in walk(\"../input/culane/driver_161_90frame\"):\n    for files in filenames :\n        if(files.split(\".\")[-1]==\"jpg\"):\n            txt_file = os.path.join(dirpath , files.split(\".\")[0]+str(\".lines.txt\") )\n            coordinates , data , mean_val , std_val  = remove_newlines(txt_file)\n            if(data is not None):\n                img_files.append(os.path.join(dirpath,files))\n                label_data.append( data )\n                mean_array.append(mean_val)\n                std_array.append(std_val)\n                coordinate_list.append(coordinates)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T22:04:06.667024Z","iopub.execute_input":"2022-06-27T22:04:06.667356Z","iopub.status.idle":"2022-06-27T22:04:50.612038Z","shell.execute_reply.started":"2022-06-27T22:04:06.667328Z","shell.execute_reply":"2022-06-27T22:04:50.611172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data visualization","metadata":{}},{"cell_type":"code","source":"#plot the image with pth corrdinates\nfig = plt.figure(figsize=(15,10))\ndef plot_data (image_file , coordinates):\n    img = cv2.imread(image_file)\n    img_rgb = cv2.cvtColor(img , cv2.COLOR_BGR2RGB)\n    for x , y in coordinates :\n        cv2.circle(img_rgb,(int(float(x)), int(float(y)) ) , 5, (0,255,0), -1)\n    plt.imshow(img_rgb)\n    plt.show()\nplot_data(img_files[0] , coordinate_list[0])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T22:04:50.613394Z","iopub.execute_input":"2022-06-27T22:04:50.613753Z","iopub.status.idle":"2022-06-27T22:04:51.123503Z","shell.execute_reply.started":"2022-06-27T22:04:50.613713Z","shell.execute_reply":"2022-06-27T22:04:51.122638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SCNN Model","metadata":{}},{"cell_type":"code","source":"import os\nresults=[]\nwith open(\"../input/train-gttext/train_gt.txt\") as f:\n    for line in f :\n        line = line.strip()\n        data = line.split(\" \")\n        set1 = data[0].split(os.path.sep)[1:]\n        if(set1[0] == \"driver_161_90frame\"):\n            results.append(data)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T22:04:51.1247Z","iopub.execute_input":"2022-06-27T22:04:51.125061Z","iopub.status.idle":"2022-06-27T22:04:51.467763Z","shell.execute_reply.started":"2022-06-27T22:04:51.125024Z","shell.execute_reply":"2022-06-27T22:04:51.46693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\ndata_set=[]\nfor data in results :\n    exist=[int(x) for x in data[2:]]\n    img_sep = data[0].split(os.path.sep)\n    label_sep = data[1].split(os.path.sep)\n    label_path = os.path.join(\"../input/culane/driver_161_90frame_labels\" , label_sep[-2], label_sep[-1])\n    img_path= os.path.join(\"../input/culane\", img_sep[1] , img_sep[2] , img_sep[3])\n    dict_culane={\n        \"img_path\":img_path ,\n        \"label_path\":label_path ,\n        \"exist\":exist \n    }\n    data_set.append(dict_culane)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T22:04:51.470778Z","iopub.execute_input":"2022-06-27T22:04:51.471151Z","iopub.status.idle":"2022-06-27T22:04:51.640092Z","shell.execute_reply.started":"2022-06-27T22:04:51.471113Z","shell.execute_reply":"2022-06-27T22:04:51.639442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#since we plan to use the pytorch then define the dataset class\nfrom torch.utils.data import Dataset\nimport torch\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import SubsetRandomSampler\nimport numpy as np\nclass CreateDataSet(Dataset):\n    def __init__(self,data_set , seed):\n        self.data_set = data_set\n        self.seed = torch.manual_seed(seed)\n        self.transform = transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((288,800)) ,\n            transforms.ToTensor(),\n            transforms.Normalize(mean = [0.485, 0.456, 0.406] , std = [0.229, 0.224, 0.225] )\n        ])\n        self.transform_label = transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((288,800)) ,\n        ])\n        self.transform_exist = transforms.Compose([\n            transforms.ToTensor()\n        ])\n    def __len__(self):\n        return len(self.data_set)\n    \n    def __getitem__(self,index):\n        data_item = self.data_set[index]\n        #read the image data\n        img = cv2.imread(data_item[\"img_path\"])\n        img_rgb = cv2.cvtColor(img , cv2.COLOR_BGR2RGB)\n        img_rgb = self.transform(img_rgb)\n        #read the label image\n        label = cv2.imread(data_item[\"label_path\"])[:,:,0]\n        label = np.array(self.transform_label(label))\n        if(len(data_item[\"exist\"]) ==4 and label is not None):\n            exists = np.array(data_item[\"exist\"])\n            \n        else:\n            exists = None\n        exists = torch.from_numpy(exists)\n        sample = {\n            \"data\":img_rgb ,\n            \"target\":label , \n            \"exist\":exists\n        }\n        \n        return sample\ntrain_data = CreateDataSet(data_set , 0)\n\nsize_train = len(train_data)\nidx_list = list(range(size_train))\nnp.random.seed(0)\nnp.random.shuffle(idx_list)\ntrain_val_split = 0.2\nsplit_index = int(size_train * train_val_split)\n\n#take the appropriate index values for train and val\ntrain_idx = idx_list[split_index :]\nval_idx = idx_list[:split_index]\n\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalidate_sampler = SubsetRandomSampler(val_idx)\n\ntrain_loader = DataLoader(train_data ,sampler=train_sampler , batch_size=16 )\nvalid_loader = DataLoader(train_data , sampler=validate_sampler , batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T22:04:51.64202Z","iopub.execute_input":"2022-06-27T22:04:51.642389Z","iopub.status.idle":"2022-06-27T22:04:53.277491Z","shell.execute_reply.started":"2022-06-27T22:04:51.642352Z","shell.execute_reply":"2022-06-27T22:04:53.276619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models","metadata":{"execution":{"iopub.status.busy":"2022-06-27T22:04:53.280522Z","iopub.execute_input":"2022-06-27T22:04:53.28105Z","iopub.status.idle":"2022-06-27T22:04:53.2862Z","shell.execute_reply.started":"2022-06-27T22:04:53.281011Z","shell.execute_reply":"2022-06-27T22:04:53.285203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SCNN(nn.Module):\n    def __init__(self , input_size , massage_kernel = 9 , pretrained=True):\n        super(SCNN , self).__init__()\n        self.pretrained = pretrained\n        self.net_init(input_size , massage_kernel)\n        self.scale_background = 0.4\n        self.scale_seg = 1.0\n        self.scale_exist = 0.1\n        \n        self.ce_loss = nn.CrossEntropyLoss(weight=torch.tensor([self.scale_background, 1, 1, 1, 1]))\n        self.bce_loss = nn.BCELoss()\n        \n    def net_init(self,input_size , ms_ks):\n        input_w , input_h = input_size\n        self.fc_input_size = 5 * int(input_w/16) * int(input_h/16)\n        self.backbone = models.vgg16_bn(pretrained=self.pretrained).features\n        \n        #replace the standard convs with dilated convs\n        for i in [34 , 37 , 40]:\n            conv = self.backbone._modules[str(i)]\n            dilated_conv = nn.Conv2d(conv.in_channels , conv.out_channels  , conv.kernel_size , \n                                    stride=conv.stride , padding = tuple(p*2 for p in conv.padding) , \n                                    dilation=2 , bias = (conv.bias is not None))\n            dilated_conv.load_state_dict(conv.state_dict())\n            self.backbone._modules[str(i)] = dilated_conv\n        self.backbone._modules.pop('33')\n        self.backbone._modules.pop('43')\n        \n        #scnn unit\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(512 , 1024 ,3 ,  padding=4 , dilation=4 , bias=False) , \n            nn.BatchNorm2d(1024) ,\n            nn.ReLU() ,\n            nn.Conv2d(1024 , 128 , 1 , bias=False),\n            nn.ReLU()\n        )\n        \n        # add message passing\n        self.message_passing = nn.ModuleList()\n        self.message_passing.add_module(\"up_down\" , nn.Conv2d( 128 , 128 , (1 , ms_ks) , padding=(0,ms_ks//2) , bias=False     ))\n        self.message_passing.add_module(\"down_up\" , nn.Conv2d(128,128,(1,ms_ks) , padding=(0,ms_ks//2) , bias=False))\n        self.message_passing.add_module('left_right',nn.Conv2d(128,128,(ms_ks , 1) , padding=(ms_ks//2 , 0) , bias=False))\n        self.message_passing.add_module(\"right_left\" , nn.Conv2d(128,128,(ms_ks , 1) , padding=(ms_ks//2 , 0) , bias=False))\n        \n        self.layer2 = nn.Sequential(\n            nn.Dropout2d(0.1) ,\n            nn.Conv2d(128,5,1)\n        )\n        self.layer3 = nn.Sequential(\n            nn.Softmax(dim=1) ,\n            #dimension reducion by 2\n            nn.AvgPool2d(2,2) ,\n        )\n        \n        self.fc = nn.Sequential(\n            nn.Linear(self.fc_input_size , 128) ,\n            nn.ReLU(),\n            nn.Linear(128,4),\n            nn.Sigmoid()\n        )\n        \n    def message_passing_forward(self , x):\n        Vertical=[True , True , False , False ]\n        Reverse = [False , True , False , True]\n        for ms_conv  , v , r in zip(self.message_passing , Vertical , Reverse):\n            x = self.message_passing_once(x  , ms_conv , v , r)\n        return x\n    \n    def message_passing_once(self,x  , ms_conv , vertical=True , reverse=True):\n        nB , C , H , W = x.shape\n        if vertical :\n            slices =[  x[: , : , i : (i+1) , : ] for i in range(H)  ]\n            dim=2\n        else :\n            slices = [ x[: , : , : , i: (i+1)] for i in range(W) ]\n            dim=3\n        if reverse :\n            slices = slices[::-1]\n            \n        #then each slice convole with the conv layer and add to the previous layer\n        out = [ slices[0]]\n        for i in range(1, len(slices)):\n            out.append(slices[i]+F.relu(ms_conv(out[i-1])))\n            \n        if reverse :\n            out = out[::-1]\n        #concatenate the tensors with the dimension\n        return torch.cat(out , dim=dim)\n    \n    def forward(self,img , seg_img=None , exist_gt=None):\n        #inference thorught the vgg16 backbone net\n        x = self.backbone(img)\n        x = self.layer1(x)\n        x = self.message_passing_forward(x)\n        x = self.layer2(x)\n        \n        #then to obtain the original image size need to upsample by 8\n        seg_pred = F.interpolate(x  , scale_factor=8 , mode='bilinear' , align_corners=True)\n        x = self.layer3(x)\n        x = x.view(-1  , self.fc_input_size)\n        exist_pred = self.fc(x)\n        \n        if seg_img is not None and exist_gt is not None:\n            loss_seg = self.ce_loss(seg_pred , seg_img.long().squeeze(1))\n            loss_exist = self.bce_loss(exist_pred.float() , exist_gt.float())\n            #nned to pay more attention on the segmanetation loss and weight should be high\n            loss = loss_seg * self.scale_seg + loss_exist * self.scale_exist\n            \n        else:\n            loss_seg = torch.tensor(0,dtype=img.dtype , device=img.device)\n            loss_exist = torch.tensor(0,dtype=img.dtype , device=img.device)\n            loss = torch.tensor(0,dtype=img.dtype , device=img.device)\n            \n        return seg_pred , exist_pred , loss_seg , loss_exist , loss\n        ","metadata":{"execution":{"iopub.status.busy":"2022-06-27T22:04:53.287917Z","iopub.execute_input":"2022-06-27T22:04:53.288398Z","iopub.status.idle":"2022-06-27T22:04:53.442301Z","shell.execute_reply.started":"2022-06-27T22:04:53.288351Z","shell.execute_reply":"2022-06-27T22:04:53.441185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define the model\nscnn_net = SCNN((800,288) , pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T22:04:53.443632Z","iopub.execute_input":"2022-06-27T22:04:53.444178Z","iopub.status.idle":"2022-06-27T22:05:28.420375Z","shell.execute_reply.started":"2022-06-27T22:04:53.444139Z","shell.execute_reply":"2022-06-27T22:05:28.41954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define the optimizer and lr optimizers\nimport torch.optim as optim\ninit_lr =  0.0001\nmax_lr = 0.01\noptimizer = optim.SGD(scnn_net.parameters() , lr=init_lr)\n#set the learining rate schedulers  scheduler need to be call for every batch operation\nscheduler = optim.lr_scheduler.CyclicLR(optimizer , base_lr=init_lr , max_lr=max_lr)\ndevice = \"cuda:0\" if torch.cuda.is_available() else 'cpu'\nscnn_net.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T22:05:28.421775Z","iopub.execute_input":"2022-06-27T22:05:28.422134Z","iopub.status.idle":"2022-06-27T22:05:32.279345Z","shell.execute_reply.started":"2022-06-27T22:05:28.422096Z","shell.execute_reply":"2022-06-27T22:05:32.278486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import namedtuple\nLabel = namedtuple( 'Label' , [\n\n        'name' ,\n\n        'id' ,\n\n        'color' ,\n        ] )","metadata":{"execution":{"iopub.status.busy":"2022-06-27T22:05:32.283589Z","iopub.execute_input":"2022-06-27T22:05:32.285838Z","iopub.status.idle":"2022-06-27T22:05:32.292918Z","shell.execute_reply.started":"2022-06-27T22:05:32.285797Z","shell.execute_reply":"2022-06-27T22:05:32.291964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [\n    #        lane mark             index       lane colour\n    Label(  'background'            ,  0 ,     (0, 0,0)        ),\n    Label(  'lane1'                 ,  1 ,     (255, 0,0)        ),\n    Label(  'lane2'                 ,  2 ,     (150, 35,232)     ),\n    Label(  'lane3'                 ,  3 ,     ( 0, 70, 70)      ),\n    Label(  'lane4'                 ,  4 ,     (102,102,255)     )        \n]","metadata":{"execution":{"iopub.status.busy":"2022-06-27T22:05:32.297543Z","iopub.execute_input":"2022-06-27T22:05:32.300007Z","iopub.status.idle":"2022-06-27T22:05:32.308756Z","shell.execute_reply.started":"2022-06-27T22:05:32.29997Z","shell.execute_reply":"2022-06-27T22:05:32.307927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\nimport numpy as np \nimport torch.nn.functional as F\n\n# PyTroch version\n\nSMOOTH = 1e-6\nfig = plt.figure(figsize=(10,10))\ndef plot_results(ori_image , result_img , result_exist , label):\n    print(\"Lane Line existing Probability : \",result_exist)\n    plot_img(ori_image)\n    plot_label(label)\n    class_image = iou_result(result_img)\n    convert(class_image)\n    return class_image\n\n\ndef iou_result(outputs):\n    # You can comment out this line if you are passing tensors of equal shape\n    # But if you are passing output from UNet or something it will most probably\n    # be with the BATCH x 1 x H x W shape\n    outputs = outputs.squeeze(0)\n    outputs = outputs.reshape(5 ,288,800)\n    outputs = torch.tensor(outputs , dtype=torch.float , device='cpu').unsqueeze(0)\n    output_prob = F.log_softmax(outputs , dim=1)\n    #take the argmax value in the dim 1\n    output_class = torch.argmax(output_prob , dim=1)\n    output_class = output_class.squeeze(0)\n    return output_class # Or thresholded.mean() if you are interested in average across the batch\n\n\ndef convert(mask):\n    mask = mask.numpy()\n    height , width = mask.shape\n    copy_img = np.zeros((height , width , 3) , dtype=np.uint8)\n    for i in range(height):\n        for j in range(width):\n            idx = mask[i][j]\n            label = labels[idx]\n            color = label.color\n            copy_img[i][j]=color\n    plt.title(\"Segment Mask\")\n    plt.imshow(copy_img)\n    plt.show()\n\ndef plot_img(image):\n    #unnormallize the image\n    image = image.reshape(3, 288,800)\n    image = np.transpose(image , (1,2,0))\n    plt.title(\"Original Image\")\n    plt.imshow(image)\n    plt.show()\n    \ndef plot_label(image):\n    #unnormallize the image\n    image = image.reshape(288,800)\n    plt.title(\"Original Image\")\n    plt.imshow(image)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T22:05:32.313361Z","iopub.execute_input":"2022-06-27T22:05:32.315638Z","iopub.status.idle":"2022-06-27T22:05:32.349434Z","shell.execute_reply.started":"2022-06-27T22:05:32.3156Z","shell.execute_reply":"2022-06-27T22:05:32.348665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import deque\n#define the train method\nEPOCHS = 3\nmean_loss        = deque(maxlen=100)\nmean_seg_loss    = deque(maxlen=100)\nmean_exist_loss  = deque(maxlen=100)\nmean_vtotal_loss = deque(maxlen=100)\nmean_vseg_loss   = deque(maxlen=100)\nmean_vexist_loss = deque(maxlen=100)\nfor epoch in range(EPOCHS):\n    e_loss_seg = 0\n    e_loss_exist = 0\n    e_loss_total =0\n    ev_loss_seg =0\n    ev_loss_exist =0\n    ev_loss_total=0\n    epoch_counter = 0\n    for sample in train_loader :\n        img_data = sample['data'].to(device)\n        label_data = sample['target'].to(device)\n        exist = sample['exist'].to(device)\n        epoch_counter += 1\n        seg_pred , exist_pred  , loss_seg , loss_exist , total_loss = scnn_net.forward(img_data , label_data , exist)\n        #cumulate the losses\n        e_loss_seg += loss_seg.to('cpu').detach().item()\n        e_loss_exist  += loss_exist.to('cpu').detach().item()\n        e_loss_total += total_loss.to('cpu').detach().item()\n        #optimize the model\n        optimizer.zero_grad()\n        total_loss.backward()\n        optimizer.step()\n        scheduler.step()\n        if((epoch_counter+1)%100==0):\n            print(\"Epoch : {} Mean Seg Loss : {:.5f} Mean Exist Loss : {:.6f} Mean Total Loss : {:.6f} \".format(epoch , \n                                                                                                        e_loss_seg/epoch_counter ,\n                                                                                                       e_loss_exist/epoch_counter,\n                                                                                                       e_loss_total/epoch_counter))\n            rand_int = np.random.choice(np.arange(len(img_data)))\n            rand_img = img_data[rand_int].unsqueeze(0)\n            label = label_data[rand_int].squeeze(0)\n            seg_pred , exist_pred , _ , _ , _ = scnn_net.forward(rand_img)\n            ori_img = rand_img.to('cpu').detach().numpy()\n            seg_pred = seg_pred.to('cpu').detach().numpy()\n            exist_pred = exist_pred.to('cpu').detach().numpy()\n            label = label.to('cpu').detach().numpy()\n            plot_results(ori_img , seg_pred , exist_pred , label)\n            \n            \n        \n    mean_seg_loss.append(e_loss_seg/len(train_loader))\n    mean_exist_loss.append(e_loss_exist/len(train_loader))\n    mean_loss.append(e_loss_total/len(train_loader))\n    \n    #validation data evaluation\n    if((epoch+1)%5==0):\n        scnn_net.eval()\n        with torch.no_grad():\n            for sample in valid_loader :\n                img_data = sample['data'].to(device)\n                label_data = sample['target'].to(device)\n                exist = sample['exist'].to(device)\n\n                seg_pred , exist_pred , loss_seg , loss_exist , loss_total = scnn_net.forward(img_data , label_data , exist)\n\n                ev_loss_seg += loss_seg.to('cpu').detach().item()\n                ev_loss_exist += loss_exist.to('cpu').detach().item()\n                ev_loss_total += loss_total.to('cpu').detach().item()\n\n            mean_vseg_loss.append(ev_loss_seg/len(valid_loader))   \n            mean_vexist_loss.append(ev_loss_exist/len(valid_loader))\n            mean_vtotal_loss.append(ev_loss_total/len(valid_loader))\n\n            #take a random sample from image\n            rand_int = np.random.choice(np.arange(len(img_data)))\n            rand_img = img_data[rand_int].unsqueeze(0)\n            seg_pred , exist_pred , _ , _ , _ = scnn_net.forward(rand_img)\n            ori_img = rand_img.to('cpu').detach().numpy()\n            seg_pred = seg_pred.to('cpu').detach().numpy()\n            exist_pred = exist_pred.to('cpu').detach().numpy()\n\n            plot_results(ori_img , seg_pred , exist_pred)\n\n        #convert model to train mode\n        scnn_net.train()\n        print(\"Validation Results\")\n        print(\"Epoch : {} Mean Seg Loss : {:.5f} Mean Exist Loss : {:.6f} Mean Total Loss : {:.6f} \".format(epoch , \n                                                                                                        np.mean(mean_vseg_loss) ,\n                                                                                                       np.mean(mean_vexist_loss),\n                                                                                                       np.mean(mean_vtotal_loss)))\n    else:\n        print(\"Epoch : {} Mean Seg Loss : {:.5f} Mean Exist Loss : {:.6f} Mean Total Loss : {:.6f} \".format(epoch , \n                                                                                                        np.mean(mean_seg_loss) ,\n                                                                                                       np.mean(mean_exist_loss),\n                                                                                                       np.mean(mean_loss)))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T22:05:32.353576Z","iopub.execute_input":"2022-06-27T22:05:32.356322Z","iopub.status.idle":"2022-06-28T03:06:18.388707Z","shell.execute_reply.started":"2022-06-27T22:05:32.356286Z","shell.execute_reply":"2022-06-28T03:06:18.387774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}